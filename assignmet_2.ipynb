{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-hamad-bakar/1st-pro/blob/main/assignmet_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXu2ibKl0KwK",
        "outputId": "9d802ed1-ca64-444e-9d9c-5d96f89d8436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n",
            "Epoch 1/10\n",
            "704/704 [==============================] - 77s 106ms/step - loss: 1.5876 - accuracy: 0.4288 - val_loss: 1.3388 - val_accuracy: 0.5286\n",
            "Epoch 2/10\n",
            "704/704 [==============================] - 57s 80ms/step - loss: 1.2384 - accuracy: 0.5674 - val_loss: 1.1367 - val_accuracy: 0.6008\n",
            "Epoch 3/10\n",
            "704/704 [==============================] - 57s 80ms/step - loss: 1.0982 - accuracy: 0.6192 - val_loss: 1.0703 - val_accuracy: 0.6230\n",
            "Epoch 4/10\n",
            "704/704 [==============================] - 55s 78ms/step - loss: 1.0056 - accuracy: 0.6530 - val_loss: 0.9706 - val_accuracy: 0.6660\n",
            "Epoch 5/10\n",
            "704/704 [==============================] - 55s 79ms/step - loss: 0.9322 - accuracy: 0.6791 - val_loss: 1.0073 - val_accuracy: 0.6514\n",
            "Epoch 6/10\n",
            "704/704 [==============================] - 57s 80ms/step - loss: 0.8826 - accuracy: 0.6932 - val_loss: 0.9458 - val_accuracy: 0.6764\n",
            "Epoch 7/10\n",
            "704/704 [==============================] - 57s 81ms/step - loss: 0.8341 - accuracy: 0.7105 - val_loss: 0.9508 - val_accuracy: 0.6742\n",
            "Epoch 8/10\n",
            "704/704 [==============================] - 57s 81ms/step - loss: 0.7986 - accuracy: 0.7242 - val_loss: 0.8849 - val_accuracy: 0.6962\n",
            "Epoch 9/10\n",
            "704/704 [==============================] - 56s 80ms/step - loss: 0.7514 - accuracy: 0.7368 - val_loss: 0.8990 - val_accuracy: 0.6930\n",
            "Epoch 10/10\n",
            "704/704 [==============================] - 56s 80ms/step - loss: 0.7224 - accuracy: 0.7496 - val_loss: 0.8689 - val_accuracy: 0.7050\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.8909 - accuracy: 0.6995\n",
            "Test accuracy: 0.6995000243186951\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize image data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "_, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNslYPm_99AI",
        "outputId": "a030de09-2d5f-48d0-ce81-7986634827c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (50000, 32, 32, 3)\n",
            "Train labels shape: (50000, 1)\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Test labels shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Print the shape of the data and labels\n",
        "print(\"Train data shape:\", x_train.shape)\n",
        "print(\"Train labels shape:\", y_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n",
        "print(\"Test labels shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDC5o6et-J0D",
        "outputId": "22ae28e1-c402-43ee-c6c2-47fd81afed91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (45000, 32, 32, 3)\n",
            "Train labels shape: (45000, 1)\n",
            "Validation data shape: (5000, 32, 32, 3)\n",
            "Validation labels shape: (5000, 1)\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Test labels shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize image data\n",
        "x_train_full = x_train_full.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Split training set into training and validation sets\n",
        "validation_split = 0.1\n",
        "num_samples = len(x_train_full)\n",
        "num_validation_samples = int(num_samples * validation_split)\n",
        "\n",
        "x_train = x_train_full[:-num_validation_samples]\n",
        "y_train = y_train_full[:-num_validation_samples]\n",
        "x_val = x_train_full[-num_validation_samples:]\n",
        "y_val = y_train_full[-num_validation_samples:]\n",
        "\n",
        "# Print the shape of the data and labels\n",
        "print(\"Train data shape:\", x_train.shape)\n",
        "print(\"Train labels shape:\", y_train.shape)\n",
        "print(\"Validation data shape:\", x_val.shape)\n",
        "print(\"Validation labels shape:\", y_val.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n",
        "print(\"Test labels shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A2wNOj4L_GdQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize image data\n",
        "x_train_full = x_train_full.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gy1VuFnLBNn8"
      },
      "outputs": [],
      "source": [
        "# (a) No validation set\n",
        "x_train_a = x_train_full\n",
        "y_train_a = y_train_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RprWIQU7BVyA"
      },
      "outputs": [],
      "source": [
        "# (b) 1 validation set with 20% of 80%\n",
        "validation_split_b = 0.2\n",
        "num_samples_b = len(x_train_full)\n",
        "num_validation_samples_b = int(num_samples_b * validation_split_b)\n",
        "\n",
        "x_train_b = x_train_full[:-num_validation_samples_b]\n",
        "y_train_b = y_train_full[:-num_validation_samples_b]\n",
        "x_val_b = x_train_full[-num_validation_samples_b:]\n",
        "y_val_b = y_train_full[-num_validation_samples_b:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0xAmNGm3BeAn"
      },
      "outputs": [],
      "source": [
        "# (c) 3-fold cross-validation set\n",
        "k_fold_c = 3\n",
        "num_samples_c = len(x_train_full)\n",
        "fold_size_c = int(num_samples_c / k_fold_c)\n",
        "\n",
        "x_train_c = []\n",
        "y_train_c = []\n",
        "x_val_c = []\n",
        "y_val_c = []\n",
        "\n",
        "for fold in range(k_fold_c):\n",
        "    start = fold * fold_size_c\n",
        "    end = (fold + 1) * fold_size_c\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "    x_train_c.append(x_train_fold)\n",
        "    y_train_c.append(y_train_fold)\n",
        "    x_val_c.append(x_val_fold)\n",
        "    y_val_c.append(y_val_fold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CrmsfsnlBlmQ"
      },
      "outputs": [],
      "source": [
        "# (d) 5-fold cross-validation set\n",
        "k_fold_d = 5\n",
        "num_samples_d = len(x_train_full)\n",
        "fold_size_d = int(num_samples_d / k_fold_d)\n",
        "\n",
        "x_train_d = []\n",
        "y_train_d = []\n",
        "x_val_d = []\n",
        "y_val_d = []\n",
        "\n",
        "for fold in range(k_fold_d):\n",
        "    start = fold * fold_size_d\n",
        "    end = (fold + 1) * fold_size_d\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "    x_train_d.append(x_train_fold)\n",
        "    y_train_d.append(y_train_fold)\n",
        "    x_val_d.append(x_val_fold)\n",
        "    y_val_d.append(y_val_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gu20ch9wBxwF"
      },
      "outputs": [],
      "source": [
        "# (e) 10-fold cross-validation set\n",
        "k_fold_e = 10\n",
        "num_samples_e = len(x_train_full)\n",
        "fold_size_e = int(num_samples_e / k_fold_e)\n",
        "\n",
        "x_train_e = []\n",
        "y_train_e = []\n",
        "x_val_e = []\n",
        "y_val_e = []\n",
        "\n",
        "for fold in range(k_fold_e):\n",
        "    start = fold * fold_size_e\n",
        "    end = (fold + 1) * fold_size_e\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "    x_train_e.append(x_train_fold)\n",
        "    y_train_e.append(y_train_fold)\n",
        "    x_val_e.append(x_val_fold)\n",
        "    y_val_e.append(y_val_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WID30olBCCCn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize image data\n",
        "x_train_full = x_train_full.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# (a) No validation set\n",
        "x_train_a = x_train_full\n",
        "y_train_a = y_train_full\n",
        "\n",
        "# (b) 1 validation set with 20% of 80%\n",
        "validation_split_b = 0.2\n",
        "num_samples_b = len(x_train_full)\n",
        "num_validation_samples_b = int(num_samples_b * validation_split_b)\n",
        "\n",
        "x_train_b = x_train_full[:-num_validation_samples_b]\n",
        "y_train_b = y_train_full[:-num_validation_samples_b]\n",
        "x_val_b = x_train_full[-num_validation_samples_b:]\n",
        "y_val_b = y_train_full[-num_validation_samples_b:]\n",
        "\n",
        "# (c) 3-fold cross-validation set\n",
        "k_fold_c = 3\n",
        "num_samples_c = len(x_train_full)\n",
        "fold_size_c = int(num_samples_c / k_fold_c)\n",
        "\n",
        "x_train_c = []\n",
        "y_train_c = []\n",
        "x_val_c = []\n",
        "y_val_c = []\n",
        "\n",
        "for fold in range(k_fold_c):\n",
        "    start = fold * fold_size_c\n",
        "    end = (fold + 1) * fold_size_c\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "\n",
        "    x_train_c.append(x_train_fold)\n",
        "    y_train_c.append(y_train_fold)\n",
        "    x_val_c.append(x_val_fold)\n",
        "    y_val_c.append(y_val_fold)\n",
        "\n",
        "\n",
        "#1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dreui7F6VfA1"
      },
      "outputs": [],
      "source": [
        "# (d) 5-fold cross-validation set\n",
        "k_fold_d = 5\n",
        "num_samples_d = len(x_train_full)\n",
        "fold_size_d = int(num_samples_d / k_fold_d)\n",
        "\n",
        "x_train_d = []\n",
        "y_train_d = []\n",
        "x_val_d = []\n",
        "y_val_d = []\n",
        "\n",
        "for fold in range(k_fold_d):\n",
        "    start = fold * fold_size_d\n",
        "    end = (fold + 1) * fold_size_d\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "\n",
        "    x_train_d.append(x_train_fold)\n",
        "    y_train_d.append(y_train_fold)\n",
        "    x_val_d.append(x_val_fold)\n",
        "    y_val_d.append(y_val_fold)\n",
        "\n",
        "# (e) 10-fold cross-validation set\n",
        "k_fold_e = 10\n",
        "num_samples_e = len(x_train_full)\n",
        "fold_size_e = int(num_samples_e / k_fold_e)\n",
        "\n",
        "x_train_e = []\n",
        "y_train_e = []\n",
        "x_val_e = []\n",
        "y_val_e = []\n",
        "\n",
        "for fold in range(k_fold_e):\n",
        "    start = fold * fold_size_e\n",
        "    end = (fold + 1) * fold_size_e\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "\n",
        "    x_train_e.append(x_train_fold)\n",
        "    y_train_e.append(y_train_fold)\n",
        "    x_val_e.append(x_val_fold)\n",
        "    y_val_e.append(y_val_fold)\n",
        "#2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6R5o_ceX2bn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize image data\n",
        "x_train_full = x_train_full.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# (a) No validation set\n",
        "x_train_a = x_train_full\n",
        "y_train_a = y_train_full\n",
        "\n",
        "# (b) 1 validation set with 20% of 80%\n",
        "validation_split_b = 0.2\n",
        "num_samples_b = len(x_train_full)\n",
        "num_validation_samples_b = int(num_samples_b * validation_split_b)\n",
        "\n",
        "x_train_b = x_train_full[:-num_validation_samples_b]\n",
        "y_train_b = y_train_full[:-num_validation_samples_b]\n",
        "x_val_b = x_train_full[-num_validation_samples_b:]\n",
        "y_val_b = y_train_full[-num_validation_samples_b:]\n",
        "\n",
        "# (c) 3-fold cross-validation set\n",
        "k_fold_c = 3\n",
        "num_samples_c = len(x_train_full)\n",
        "fold_size_c = int(num_samples_c / k_fold_c)\n",
        "\n",
        "x_train_c = []\n",
        "y_train_c = []\n",
        "x_val_c = []\n",
        "y_val_c = []\n",
        "\n",
        "for fold in range(k_fold_c):\n",
        "    start = fold * fold_size_c\n",
        "    end = (fold + 1) * fold_size_c\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "\n",
        "    x_train_c.append(x_train_fold)\n",
        "    y_train_c.append(y_train_fold)\n",
        "    x_val_c.append(x_val_fold)\n",
        "    y_val_c.append(y_val_fold)\n",
        "\n",
        "# (d) 5-fold cross-validation set\n",
        "k_fold_d = 5\n",
        "num_samples_d = len(x_train_full)\n",
        "fold_size_d = int(num_samples_d / k_fold_d)\n",
        "\n",
        "x_train_d = []\n",
        "y_train_d = []\n",
        "x_val_d = []\n",
        "y_val_d = []\n",
        "\n",
        "for fold in range(k_fold_d):\n",
        "    start = fold * fold_size_d\n",
        "    end = (fold + 1) * fold_size_d\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "\n",
        "    x_train_d.append(x_train_fold)\n",
        "    y_train_d.append(y_train_fold)\n",
        "    x_val_d.append(x_val_fold)\n",
        "    y_val_d.append(y_val_fold)\n",
        "\n",
        "# (e) 10-fold cross-validation set\n",
        "k_fold_e = 10\n",
        "num_samples_e = len(x_train_full)\n",
        "fold_size_e = int(num_samples_e / k_fold_e)\n",
        "\n",
        "x_train_e = []\n",
        "y_train_e = []\n",
        "x_val_e = []\n",
        "y_val_e = []\n",
        "\n",
        "for fold in range(k_fold_e):\n",
        "    start = fold * fold_size_e\n",
        "    end = (fold + 1) * fold_size_e\n",
        "\n",
        "    x_val_fold = x_train_full[start:end]\n",
        "    y_val_fold = y_train_full[start:end]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:start], x_train_full[end:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:start], y_train_full[end:]], axis=0)\n",
        "\n",
        "    x_train_e.append(x_train_fold)\n",
        "    y_train_e.append(y_train_fold)\n",
        "    x_val_e.append(x_val_fold)\n",
        "    y_val_e.append(y_val_fold)\n",
        "\n",
        "# (f) Leave-one-out cross-validation set\n",
        "k_fold_f = num_samples_e\n",
        "x_train_f = []\n",
        "y_train_f = []\n",
        "x_val_f = []\n",
        "y_val_f = []\n",
        "\n",
        "for fold in range(k_fold_f):\n",
        "    x_val_fold = x_train_full[fold]\n",
        "    y_val_fold = y_train_full[fold]\n",
        "\n",
        "    x_train_fold = np.concatenate([x_train_full[:fold], x_train_full[fold + 1:]], axis=0)\n",
        "    y_train_fold = np.concatenate([y_train_full[:fold], y_train_full[fold + 1:]], axis=0)\n",
        "\n",
        "    x_train_f.append(x_train_fold)\n",
        "    y_train_f.append(y_train_fold)\n",
        "    x_val_f.append(x_val_fold)\n",
        "    y_val_f.append(y_val_fold)\n",
        "\n",
        "\n",
        "# Print the shape of the data and labels for each scenario\n",
        "print(\"(a) No validation set\")\n",
        "print(\"Sorry, but it seems that\")\n",
        "print(\"Train data shape:\", x_train_a.shape)\n",
        "print(\"Train labels shape:\", y_train_a.shape)\n",
        "\n",
        "print(\"(b) 1 validation set with 20% of 80%\")\n",
        "print(\"Train data shape:\", x_train_b.shape)\n",
        "print(\"Train labels shape:\", y_train_b.shape)\n",
        "print(\"Validation data shape:\", x_val_b.shape)\n",
        "print(\"Validation labels shape:\", y_val_b.shape)\n",
        "\n",
        "print(\"(c) 3-fold cross-validation set\")\n",
        "for fold in range(k_fold_c):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    print(\"Train data shape:\", x_train_c[fold].shape)\n",
        "    print(\"Train labels shape:\", y_train_c[fold].shape)\n",
        "    print(\"Validation data shape:\", x_val_c[fold].shape)\n",
        "    print(\"Validation labels shape:\", y_val_c[fold].shape)\n",
        "\n",
        "print(\"(d) 5-fold cross-validation set\")\n",
        "for fold in range(k_fold_d):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    print(\"Train data shape:\", x_train_d[fold].shape)\n",
        "    print(\"Train labels shape:\", y_train_d[fold].shape)\n",
        "    print(\"Validation data shape:\", x_val_d[fold].shape)\n",
        "    print(\"Validation labels shape:\", y_val_d[fold].shape)\n",
        "\n",
        "print(\"(e) 10-fold cross-validation set\")\n",
        "for fold in range(k_fold_e):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    print(\"Train data shape:\", x_train_e[fold].shape)\n",
        "    print(\"Train labels shape:\", y_train_e[fold].shape)\n",
        "    print(\"Validation data shape:\", x_val_e[fold].shape)\n",
        "    print(\"Validation labels shape:\", y_val_e[fold].shape)\n",
        "\n",
        "print(\"(f) Leave-one-out cross-validation set\")\n",
        "for fold in range(k_fold_f):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    print(\"Train data shape:\", x_train_f[fold].shape)\n",
        "    print(\"Train labels shape:\", y_train_f[fold].shape)\n",
        "    print(\"Validation data shape:\", x_val_f[fold].shape)\n",
        "    print(\"Validation labels shape:\", y_val_f[fold].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOOenH7UbOg-",
        "outputId": "a331aea6-b498-4193-b6f3-9817559dfa88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9722222222222222\n",
            "k-NN Accuracy: 0.9861111111111112\n",
            "Naive Bayes Accuracy: 0.8472222222222222\n",
            "Decision Tree Accuracy: 0.8416666666666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the digits dataset\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "\n",
        "# k-Nearest Neighbors (k-NN)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "knn_predictions = knn_classifier.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(\"k-NN Accuracy:\", knn_accuracy)\n",
        "\n",
        "# Naive Bayes\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "nb_predictions = nb_classifier.predict(X_test)\n",
        "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
        "\n",
        "# Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "dt_predictions = dt_classifier.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjA4BgSYlQFp",
        "outputId": "a94b09e8-dc2c-40aa-b795-57b1abbc8efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      0.94      0.97        34\n",
            "           4       0.98      1.00      0.99        46\n",
            "           5       0.94      0.96      0.95        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       0.97      0.97      0.97        34\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n",
            "k-NN Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       0.98      1.00      0.99        46\n",
            "           5       0.98      0.96      0.97        47\n",
            "           6       0.97      1.00      0.99        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       1.00      1.00      1.00        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "Naive Bayes Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        33\n",
            "           1       0.83      0.86      0.84        28\n",
            "           2       0.91      0.61      0.73        33\n",
            "           3       0.91      0.85      0.88        34\n",
            "           4       0.97      0.83      0.89        46\n",
            "           5       0.90      0.94      0.92        47\n",
            "           6       0.92      0.97      0.94        35\n",
            "           7       0.69      0.97      0.80        34\n",
            "           8       0.57      0.87      0.68        30\n",
            "           9       0.96      0.65      0.78        40\n",
            "\n",
            "    accuracy                           0.85       360\n",
            "   macro avg       0.86      0.85      0.84       360\n",
            "weighted avg       0.88      0.85      0.85       360\n",
            "\n",
            "Decision Tree Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.88      0.92        33\n",
            "           1       0.85      0.79      0.81        28\n",
            "           2       0.86      0.73      0.79        33\n",
            "           3       0.76      0.85      0.81        34\n",
            "           4       0.84      0.91      0.87        46\n",
            "           5       0.89      0.85      0.87        47\n",
            "           6       0.97      0.91      0.94        35\n",
            "           7       0.82      0.91      0.86        34\n",
            "           8       0.75      0.70      0.72        30\n",
            "           9       0.75      0.82      0.79        40\n",
            "\n",
            "    accuracy                           0.84       360\n",
            "   macro avg       0.84      0.84      0.84       360\n",
            "weighted avg       0.85      0.84      0.84       360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "rf_report = classification_report(y_test, rf_predictions)\n",
        "print(\"Random Forest Metrics:\")\n",
        "print(rf_report)\n",
        "\n",
        "# Evaluate k-Nearest Neighbors (k-NN)\n",
        "knn_predictions = knn_classifier.predict(X_test)\n",
        "knn_report = classification_report(y_test, knn_predictions)\n",
        "print(\"k-NN Metrics:\")\n",
        "print(knn_report)\n",
        "\n",
        "# Evaluate Naive Bayes\n",
        "nb_predictions = nb_classifier.predict(X_test)\n",
        "nb_report = classification_report(y_test, nb_predictions)\n",
        "print(\"Naive Bayes Metrics:\")\n",
        "print(nb_report)\n",
        "\n",
        "# Evaluate Decision Tree\n",
        "dt_predictions = dt_classifier.predict(X_test)\n",
        "dt_report = classification_report(y_test, dt_predictions)\n",
        "print(\"Decision Tree Metrics:\")\n",
        "print(dt_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72DQ-UgIlVWB",
        "outputId": "3b3ad7fb-4efd-47c0-82d1-4832319d9c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Confusion Matrix:\n",
            "[[32  0  0  0  1  0  0  0  0  0]\n",
            " [ 0 28  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 33  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 32  0  1  0  0  1  0]\n",
            " [ 0  0  0  0 46  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 45  1  0  0  1]\n",
            " [ 0  0  0  0  0  1 34  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 33  0  1]\n",
            " [ 0  1  0  0  0  0  0  0 29  0]\n",
            " [ 0  0  0  0  0  1  0  1  0 38]]\n",
            "k-NN Confusion Matrix:\n",
            "[[33  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 28  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 33  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 34  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 46  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 45  1  0  0  1]\n",
            " [ 0  0  0  0  0  0 35  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 33  0  1]\n",
            " [ 0  0  0  0  0  0  0  0 30  0]\n",
            " [ 0  0  0  0  1  1  0  0  0 38]]\n",
            "Naive Bayes Confusion Matrix:\n",
            "[[31  0  0  0  0  1  0  1  0  0]\n",
            " [ 0 24  0  0  0  0  0  0  3  1]\n",
            " [ 0  2 20  0  0  0  1  0 10  0]\n",
            " [ 0  0  1 29  0  1  0  0  3  0]\n",
            " [ 0  0  0  0 38  0  1  7  0  0]\n",
            " [ 0  0  0  1  0 44  1  1  0  0]\n",
            " [ 0  0  0  0  1  0 34  0  0  0]\n",
            " [ 0  0  0  0  0  1  0 33  0  0]\n",
            " [ 0  2  0  0  0  0  0  2 26  0]\n",
            " [ 0  1  1  2  0  2  0  4  4 26]]\n",
            "Decision Tree Confusion Matrix:\n",
            "[[29  0  0  0  2  1  0  0  0  1]\n",
            " [ 0 22  1  0  1  0  0  1  2  1]\n",
            " [ 0  0 24  3  1  1  1  1  2  0]\n",
            " [ 0  0  1 29  0  1  0  1  1  1]\n",
            " [ 0  0  1  0 42  0  0  2  1  0]\n",
            " [ 0  0  1  0  1 40  0  0  1  4]\n",
            " [ 1  0  0  0  1  1 32  0  0  0]\n",
            " [ 0  0  0  2  1  0  0 31  0  0]\n",
            " [ 0  3  0  1  0  1  0  0 21  4]\n",
            " [ 0  1  0  3  1  0  0  2  0 33]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Confusion matrix for Random Forest\n",
        "rf_cm = confusion_matrix(y_test, rf_predictions)\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(rf_cm)\n",
        "\n",
        "# Confusion matrix for k-Nearest Neighbors (k-NN)\n",
        "knn_cm = confusion_matrix(y_test, knn_predictions)\n",
        "print(\"k-NN Confusion Matrix:\")\n",
        "print(knn_cm)\n",
        "\n",
        "# Confusion matrix for Naive Bayes\n",
        "nb_cm = confusion_matrix(y_test, nb_predictions)\n",
        "print(\"Naive Bayes Confusion Matrix:\")\n",
        "print(nb_cm)\n",
        "\n",
        "# Confusion matrix for Decision Tree\n",
        "dt_cm = confusion_matrix(y_test, dt_predictions)\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(dt_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWrp_g34n9iq",
        "outputId": "4a527502-b454-4344-c1ec-1535d3e5803c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Class: 0\n",
            "Accuracy: 0.9696969696969697\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        33\n",
            "           4       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97        33\n",
            "   macro avg       0.50      0.48      0.49        33\n",
            "weighted avg       1.00      0.97      0.98        33\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 0\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "\n",
            "    accuracy                           1.00        33\n",
            "   macro avg       1.00      1.00      1.00        33\n",
            "weighted avg       1.00      1.00      1.00        33\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 0\n",
            "Accuracy: 0.9393939393939394\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        33\n",
            "           5       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.94        33\n",
            "   macro avg       0.33      0.31      0.32        33\n",
            "weighted avg       1.00      0.94      0.97        33\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 0\n",
            "Accuracy: 0.8787878787878788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94        33\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.88        33\n",
            "   macro avg       0.25      0.22      0.23        33\n",
            "weighted avg       1.00      0.88      0.94        33\n",
            "\n",
            "----------------------\n",
            "Random Forest - Class: 1\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        28\n",
            "\n",
            "    accuracy                           1.00        28\n",
            "   macro avg       1.00      1.00      1.00        28\n",
            "weighted avg       1.00      1.00      1.00        28\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 1\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        28\n",
            "\n",
            "    accuracy                           1.00        28\n",
            "   macro avg       1.00      1.00      1.00        28\n",
            "weighted avg       1.00      1.00      1.00        28\n",
            "\n",
            "----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes - Class: 1\n",
            "Accuracy: 0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        28\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.86        28\n",
            "   macro avg       0.33      0.29      0.31        28\n",
            "weighted avg       1.00      0.86      0.92        28\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 1\n",
            "Accuracy: 0.7857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.79      0.88        28\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.79        28\n",
            "   macro avg       0.17      0.13      0.15        28\n",
            "weighted avg       1.00      0.79      0.88        28\n",
            "\n",
            "----------------------\n",
            "Random Forest - Class: 2\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00        33\n",
            "\n",
            "    accuracy                           1.00        33\n",
            "   macro avg       1.00      1.00      1.00        33\n",
            "weighted avg       1.00      1.00      1.00        33\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 2\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00        33\n",
            "\n",
            "    accuracy                           1.00        33\n",
            "   macro avg       1.00      1.00      1.00        33\n",
            "weighted avg       1.00      1.00      1.00        33\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 2\n",
            "Accuracy: 0.6060606060606061\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       1.00      0.61      0.75        33\n",
            "           6       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.61        33\n",
            "   macro avg       0.25      0.15      0.19        33\n",
            "weighted avg       1.00      0.61      0.75        33\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 2\n",
            "Accuracy: 0.7272727272727273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.73      0.84        33\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.73        33\n",
            "   macro avg       0.14      0.10      0.12        33\n",
            "weighted avg       1.00      0.73      0.84        33\n",
            "\n",
            "----------------------\n",
            "Random Forest - Class: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9411764705882353\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       1.00      0.94      0.97        34\n",
            "           5       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.94        34\n",
            "   macro avg       0.33      0.31      0.32        34\n",
            "weighted avg       1.00      0.94      0.97        34\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 3\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       1.00      1.00      1.00        34\n",
            "\n",
            "    accuracy                           1.00        34\n",
            "   macro avg       1.00      1.00      1.00        34\n",
            "weighted avg       1.00      1.00      1.00        34\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 3\n",
            "Accuracy: 0.8529411764705882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       1.00      0.85      0.92        34\n",
            "           5       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.85        34\n",
            "   macro avg       0.25      0.21      0.23        34\n",
            "weighted avg       1.00      0.85      0.92        34\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 3\n",
            "Accuracy: 0.8529411764705882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       1.00      0.85      0.92        34\n",
            "           5       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.85        34\n",
            "   macro avg       0.17      0.14      0.15        34\n",
            "weighted avg       1.00      0.85      0.92        34\n",
            "\n",
            "----------------------\n",
            "Random Forest - Class: 4\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       1.00      1.00      1.00        46\n",
            "\n",
            "    accuracy                           1.00        46\n",
            "   macro avg       1.00      1.00      1.00        46\n",
            "weighted avg       1.00      1.00      1.00        46\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 4\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       1.00      1.00      1.00        46\n",
            "\n",
            "    accuracy                           1.00        46\n",
            "   macro avg       1.00      1.00      1.00        46\n",
            "weighted avg       1.00      1.00      1.00        46\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 4\n",
            "Accuracy: 0.8260869565217391\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       1.00      0.83      0.90        46\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.83        46\n",
            "   macro avg       0.33      0.28      0.30        46\n",
            "weighted avg       1.00      0.83      0.90        46\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 4\n",
            "Accuracy: 0.9130434782608695\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       1.00      0.91      0.95        46\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.91        46\n",
            "   macro avg       0.25      0.23      0.24        46\n",
            "weighted avg       1.00      0.91      0.95        46\n",
            "\n",
            "----------------------\n",
            "Random Forest - Class: 5\n",
            "Accuracy: 0.9574468085106383\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       1.00      0.96      0.98        47\n",
            "           6       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96        47\n",
            "   macro avg       0.33      0.32      0.33        47\n",
            "weighted avg       1.00      0.96      0.98        47\n",
            "\n",
            "----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-NN - Class: 5\n",
            "Accuracy: 0.9574468085106383\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       1.00      0.96      0.98        47\n",
            "           6       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96        47\n",
            "   macro avg       0.33      0.32      0.33        47\n",
            "weighted avg       1.00      0.96      0.98        47\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 5\n",
            "Accuracy: 0.9361702127659575\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         0\n",
            "           5       1.00      0.94      0.97        47\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.94        47\n",
            "   macro avg       0.25      0.23      0.24        47\n",
            "weighted avg       1.00      0.94      0.97        47\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 5\n",
            "Accuracy: 0.851063829787234\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       1.00      0.85      0.92        47\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.85        47\n",
            "   macro avg       0.20      0.17      0.18        47\n",
            "weighted avg       1.00      0.85      0.92        47\n",
            "\n",
            "----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Class: 6\n",
            "Accuracy: 0.9714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       1.00      0.97      0.99        35\n",
            "\n",
            "    accuracy                           0.97        35\n",
            "   macro avg       0.50      0.49      0.49        35\n",
            "weighted avg       1.00      0.97      0.99        35\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 6\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           6       1.00      1.00      1.00        35\n",
            "\n",
            "    accuracy                           1.00        35\n",
            "   macro avg       1.00      1.00      1.00        35\n",
            "weighted avg       1.00      1.00      1.00        35\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 6\n",
            "Accuracy: 0.9714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       0.00      0.00      0.00         0\n",
            "           6       1.00      0.97      0.99        35\n",
            "\n",
            "    accuracy                           0.97        35\n",
            "   macro avg       0.50      0.49      0.49        35\n",
            "weighted avg       1.00      0.97      0.99        35\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 6\n",
            "Accuracy: 0.9142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       1.00      0.91      0.96        35\n",
            "\n",
            "    accuracy                           0.91        35\n",
            "   macro avg       0.25      0.23      0.24        35\n",
            "weighted avg       1.00      0.91      0.96        35\n",
            "\n",
            "----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Class: 7\n",
            "Accuracy: 0.9705882352941176\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           7       1.00      0.97      0.99        34\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97        34\n",
            "   macro avg       0.50      0.49      0.49        34\n",
            "weighted avg       1.00      0.97      0.99        34\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 7\n",
            "Accuracy: 0.9705882352941176\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           7       1.00      0.97      0.99        34\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97        34\n",
            "   macro avg       0.50      0.49      0.49        34\n",
            "weighted avg       1.00      0.97      0.99        34\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 7\n",
            "Accuracy: 0.9705882352941176\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       0.00      0.00      0.00         0\n",
            "           7       1.00      0.97      0.99        34\n",
            "\n",
            "    accuracy                           0.97        34\n",
            "   macro avg       0.50      0.49      0.49        34\n",
            "weighted avg       1.00      0.97      0.99        34\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 7\n",
            "Accuracy: 0.9117647058823529\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           7       1.00      0.91      0.95        34\n",
            "\n",
            "    accuracy                           0.91        34\n",
            "   macro avg       0.33      0.30      0.32        34\n",
            "weighted avg       1.00      0.91      0.95        34\n",
            "\n",
            "----------------------\n",
            "Random Forest - Class: 8\n",
            "Accuracy: 0.9666666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           8       1.00      0.97      0.98        30\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.50      0.48      0.49        30\n",
            "weighted avg       1.00      0.97      0.98        30\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 8\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           8       1.00      1.00      1.00        30\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes - Class: 8\n",
            "Accuracy: 0.8666666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       1.00      0.87      0.93        30\n",
            "\n",
            "    accuracy                           0.87        30\n",
            "   macro avg       0.33      0.29      0.31        30\n",
            "weighted avg       1.00      0.87      0.93        30\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 8\n",
            "Accuracy: 0.7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           8       1.00      0.70      0.82        30\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.70        30\n",
            "   macro avg       0.20      0.14      0.16        30\n",
            "weighted avg       1.00      0.70      0.82        30\n",
            "\n",
            "----------------------\n",
            "Random Forest - Class: 9\n",
            "Accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           9       1.00      0.95      0.97        40\n",
            "\n",
            "    accuracy                           0.95        40\n",
            "   macro avg       0.33      0.32      0.32        40\n",
            "weighted avg       1.00      0.95      0.97        40\n",
            "\n",
            "----------------------\n",
            "k-NN - Class: 9\n",
            "Accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           9       1.00      0.95      0.97        40\n",
            "\n",
            "    accuracy                           0.95        40\n",
            "   macro avg       0.33      0.32      0.32        40\n",
            "weighted avg       1.00      0.95      0.97        40\n",
            "\n",
            "----------------------\n",
            "Naive Bayes - Class: 9\n",
            "Accuracy: 0.65\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       1.00      0.65      0.79        40\n",
            "\n",
            "    accuracy                           0.65        40\n",
            "   macro avg       0.14      0.09      0.11        40\n",
            "weighted avg       1.00      0.65      0.79        40\n",
            "\n",
            "----------------------\n",
            "Decision Tree - Class: 9\n",
            "Accuracy: 0.825\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           9       1.00      0.82      0.90        40\n",
            "\n",
            "    accuracy                           0.82        40\n",
            "   macro avg       0.20      0.16      0.18        40\n",
            "weighted avg       1.00      0.82      0.90        40\n",
            "\n",
            "----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define class labels\n",
        "class_labels = np.unique(y_test)\n",
        "\n",
        "# Analyze performance for each class\n",
        "for class_label in class_labels:\n",
        "    # Random Forest\n",
        "    rf_class_predictions = rf_predictions[y_test == class_label]\n",
        "    rf_class_true = y_test[y_test == class_label]\n",
        "    rf_class_accuracy = accuracy_score(rf_class_true, rf_class_predictions)\n",
        "    rf_class_report = classification_report(rf_class_true, rf_class_predictions)\n",
        "    print(\"Random Forest - Class:\", class_label)\n",
        "    print(\"Accuracy:\", rf_class_accuracy)\n",
        "    print(rf_class_report)\n",
        "    print(\"----------------------\")\n",
        "\n",
        "    # k-Nearest Neighbors (k-NN)\n",
        "    knn_class_predictions = knn_predictions[y_test == class_label]\n",
        "    knn_class_true = y_test[y_test == class_label]\n",
        "    knn_class_accuracy = accuracy_score(knn_class_true, knn_class_predictions)\n",
        "    knn_class_report = classification_report(knn_class_true, knn_class_predictions)\n",
        "    print(\"k-NN - Class:\", class_label)\n",
        "    print(\"Accuracy:\", knn_class_accuracy)\n",
        "    print(knn_class_report)\n",
        "    print(\"----------------------\")\n",
        "\n",
        "    # Naive Bayes\n",
        "    nb_class_predictions = nb_predictions[y_test == class_label]\n",
        "    nb_class_true = y_test[y_test == class_label]\n",
        "    nb_class_accuracy = accuracy_score(nb_class_true, nb_class_predictions)\n",
        "    nb_class_report = classification_report(nb_class_true, nb_class_predictions)\n",
        "    print(\"Naive Bayes - Class:\", class_label)\n",
        "    print(\"Accuracy:\", nb_class_accuracy)\n",
        "    print(nb_class_report)\n",
        "    print(\"----------------------\")\n",
        "\n",
        "    # Decision Tree\n",
        "    dt_class_predictions = dt_predictions[y_test == class_label]\n",
        "    dt_class_true = y_test[y_test == class_label]\n",
        "    dt_class_accuracy = accuracy_score(dt_class_true, dt_class_predictions)\n",
        "    dt_class_report = classification_report(dt_class_true, dt_class_predictions)\n",
        "    print(\"Decision Tree - Class:\", class_label)\n",
        "    print(\"Accuracy:\", dt_class_accuracy)\n",
        "    print(dt_class_report)\n",
        "    print(\"----------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P3CT08NIpRRr",
        "outputId": "352409a5-ccd2-4fe8-8b2e-856fe7537b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-66771a1d644c>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf_model_gray.fit(x_train_gray, y_train)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grayscale Image Results:\n",
            "Random Forest Accuracy: 0.407\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.41      0.42       973\n",
            "           1       0.43      0.49      0.46       979\n",
            "           2       0.34      0.30      0.32      1030\n",
            "           3       0.32      0.23      0.27      1023\n",
            "           4       0.32      0.39      0.35       933\n",
            "           5       0.38      0.34      0.36      1015\n",
            "           6       0.41      0.42      0.41       996\n",
            "           7       0.46      0.43      0.45       994\n",
            "           8       0.46      0.52      0.49      1017\n",
            "           9       0.48      0.54      0.51      1040\n",
            "\n",
            "    accuracy                           0.41     10000\n",
            "   macro avg       0.40      0.41      0.40     10000\n",
            "weighted avg       0.40      0.41      0.40     10000\n",
            "\n",
            "-----------------------------------------\n",
            "k-Nearest Neighbors Accuracy: 0.2769\n",
            "k-Nearest Neighbors Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.45      0.28       973\n",
            "           1       0.57      0.18      0.27       979\n",
            "           2       0.21      0.36      0.27      1030\n",
            "           3       0.28      0.18      0.22      1023\n",
            "           4       0.19      0.36      0.25       933\n",
            "           5       0.41      0.19      0.26      1015\n",
            "           6       0.31      0.20      0.24       996\n",
            "           7       0.69      0.16      0.27       994\n",
            "           8       0.31      0.58      0.40      1017\n",
            "           9       0.68      0.11      0.19      1040\n",
            "\n",
            "    accuracy                           0.28     10000\n",
            "   macro avg       0.39      0.28      0.27     10000\n",
            "weighted avg       0.39      0.28      0.27     10000\n",
            "\n",
            "-----------------------------------------\n",
            "Naive Bayes Accuracy: 0.2574\n",
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.41      0.27       973\n",
            "           1       0.29      0.14      0.19       979\n",
            "           2       0.21      0.07      0.11      1030\n",
            "           3       0.25      0.08      0.12      1023\n",
            "           4       0.21      0.42      0.28       933\n",
            "           5       0.30      0.24      0.26      1015\n",
            "           6       0.23      0.40      0.29       996\n",
            "           7       0.36      0.10      0.15       994\n",
            "           8       0.30      0.35      0.33      1017\n",
            "           9       0.39      0.39      0.39      1040\n",
            "\n",
            "    accuracy                           0.26     10000\n",
            "   macro avg       0.27      0.26      0.24     10000\n",
            "weighted avg       0.27      0.26      0.24     10000\n",
            "\n",
            "-----------------------------------------\n",
            "Decision Tree Accuracy: 0.2264\n",
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.26      0.25       973\n",
            "           1       0.26      0.25      0.25       979\n",
            "           2       0.18      0.18      0.18      1030\n",
            "           3       0.18      0.17      0.18      1023\n",
            "           4       0.17      0.19      0.18       933\n",
            "           5       0.21      0.21      0.21      1015\n",
            "           6       0.21      0.21      0.21       996\n",
            "           7       0.23      0.22      0.23       994\n",
            "           8       0.29      0.30      0.29      1017\n",
            "           9       0.29      0.27      0.28      1040\n",
            "\n",
            "    accuracy                           0.23     10000\n",
            "   macro avg       0.23      0.23      0.23     10000\n",
            "weighted avg       0.23      0.23      0.23     10000\n",
            "\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [50000, 40000]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-66771a1d644c>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Train Random Forest model on color images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mrf_model_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mrf_model_color\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mrf_predictions_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model_color\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [50000, 40000]"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Convert color images to grayscale\n",
        "x_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in x_train])\n",
        "x_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in x_test])\n",
        "\n",
        "# Resize grayscale images to match the dimensions of color images\n",
        "x_train_gray = np.resize(x_train_gray, (x_train_gray.shape[0], 32, 32))\n",
        "x_test_gray = np.resize(x_test_gray, (x_test_gray.shape[0], 32, 32))\n",
        "\n",
        "# Split grayscale dataset into training and testing sets\n",
        "x_train_gray, x_val_gray, y_train, y_val = train_test_split(x_train_gray, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape grayscale images to flatten them\n",
        "x_train_gray = x_train_gray.reshape(x_train_gray.shape[0], -1)\n",
        "x_val_gray = x_val_gray.reshape(x_val_gray.shape[0], -1)\n",
        "x_test_gray = x_test_gray.reshape(x_test_gray.shape[0], -1)\n",
        "\n",
        "# Train Random Forest model on grayscale images\n",
        "rf_model_gray = RandomForestClassifier()\n",
        "rf_model_gray.fit(x_train_gray, y_train)\n",
        "rf_predictions_gray = rf_model_gray.predict(x_val_gray)\n",
        "\n",
        "# Train k-Nearest Neighbors model on grayscale images\n",
        "knn_model_gray = KNeighborsClassifier()\n",
        "knn_model_gray.fit(x_train_gray, y_train)\n",
        "knn_predictions_gray = knn_model_gray.predict(x_val_gray)\n",
        "\n",
        "# Train Naive Bayes model on grayscale images\n",
        "nb_model_gray = GaussianNB()\n",
        "nb_model_gray.fit(x_train_gray, y_train)\n",
        "nb_predictions_gray = nb_model_gray.predict(x_val_gray)\n",
        "\n",
        "# Train Decision Tree model on grayscale images\n",
        "dt_model_gray = DecisionTreeClassifier()\n",
        "dt_model_gray.fit(x_train_gray, y_train)\n",
        "dt_predictions_gray = dt_model_gray.predict(x_val_gray)\n",
        "\n",
        "# Evaluate performance on grayscale images\n",
        "print(\"Grayscale Image Results:\")\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_val, rf_predictions_gray))\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_val, rf_predictions_gray))\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"k-Nearest Neighbors Accuracy:\", accuracy_score(y_val, knn_predictions_gray))\n",
        "print(\"k-Nearest Neighbors Classification Report:\")\n",
        "print(classification_report(y_val, knn_predictions_gray))\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_val, nb_predictions_gray))\n",
        "print(\"Naive Bayes Classification Report:\")\n",
        "print(classification_report(y_val, nb_predictions_gray))\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_val, dt_predictions_gray))\n",
        "print(\"Decision Tree Classification Report:\")\n",
        "print(classification_report(y_val, dt_predictions_gray))\n",
        "print(\"-----------------------------------------\")\n",
        "\n",
        "# Train Random Forest model on color images\n",
        "rf_model_color = RandomForestClassifier()\n",
        "rf_model_color.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
        "rf_predictions_color = rf_model_color.predict(x_val.reshape(x_val.shape[0], -1))\n",
        "\n",
        "# Train k-Nearest Neighbors model on color images\n",
        "knn_model_color = KNeighborsClassifier()\n",
        "knn_model_color.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
        "knn_predictions_color = knn_model_color.predict(x_val.reshape(x_val.shape[0], -1))\n",
        "\n",
        "# Train Naive Bayes model on color images\n",
        "nb_model_color = GaussianNB()\n",
        "nb_model_color.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
        "nb_predictions_color = nb_model_color.predict(x_val.reshape(x_val.shape[0], -1))\n",
        "\n",
        "# Train Decision Tree model on color images\n",
        "dt_model_color = DecisionTreeClassifier()\n",
        "dt_model_color.fit(x_train.reshape(x_train.shape[0], -1), y_train)\n",
        "dt_predictions_color = dt_model_color.predict(x_val.reshape(x_val.shape[0], -1))\n",
        "\n",
        "# Evaluate performance on color images\n",
        "print(\"Color Image Results:\")\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_val, rf_predictions_color))\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_val, rf_predictions_color))\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"k-Nearest Neighbors Accuracy:\", accuracy_score(y_val, knn_predictions_color))\n",
        "print(\"k-Nearest Neighbors Classification Report:\")\n",
        "print(classification_report(y_val, knn_predictions_color))\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_val, nb_predictions_color))\n",
        "print(\"Naive Bayes Classification Report:\")\n",
        "print(classification_report(y_val, nb_predictions_color))\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_val, dt_predictions_color))\n",
        "print(\"Decision Tree Classification Report:\")\n",
        "print(classification_report(y_val, dt_predictions_color))\n",
        "print(\"-----------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPCOlWu5HiBLoPHbXjPhAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}